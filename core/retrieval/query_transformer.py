from __future__ import annotations

import logging
from dataclasses import dataclass
from typing import List, Optional, Dict, Any

from llama_index.core import Settings
from llama_index.core.llms import LLM, ChatMessage, MessageRole
from llama_index.core.schema import NodeWithScore

from core.retrieval.dual_retriever import (
    DualRetriever,
    DualRetrieverConfig,
    DualRetrieverResult,   # üëà nom corrig√©
    get_default_dual_retriever,
)

logger = logging.getLogger(__name__)


# ----------------------------------------------------------------------
# 0. Config & r√©sultat RAG Fusion
# ----------------------------------------------------------------------
@dataclass
class QueryTransformerConfig:
    """
    Config pour le module de RAG Fusion :
      - enabled : activer/d√©sactiver la g√©n√©ration de variantes
      - num_variants : nombre de reformulations √† g√©n√©rer (question incluse)
      - temperature : temp√©rature du LLM pour la g√©n√©ration
    """

    enabled: bool = True
    num_variants: int = 4
    temperature: float = 0.3


@dataclass
class RAGFusionQueryResult:
    """
    R√©sultat du QueryTransformer avec RAG Fusion :
      - vector_nodes : passages r√©cup√©r√©s via la voie vectorielle
      - kg_facts : faits r√©cup√©r√©s via la voie KG
      - all_queries : liste (question originale + variantes)
    """

    vector_nodes: List[NodeWithScore]
    kg_facts: List[Dict[str, Any]]
    all_queries: List[str]


# ----------------------------------------------------------------------
# 1. Impl√©mentation RAG Fusion
# ----------------------------------------------------------------------
class RAGFusionQueryTransformer:
    """
    Utilise un LLM (Settings.llm ou fourni) pour g√©n√©rer plusieurs variantes
    de la requ√™te utilisateur, puis appelle le DualRetriever sur chacune.

    Logique :
      1) G√©n√®re N requ√™tes (question + reformulations)
      2) Appelle DualRetriever.retrieve(query) pour chaque requ√™te
      3) Fusionne les r√©sultats (d√©duplication + agr√©gation)
    """

    def __init__(
        self,
        config: Optional[QueryTransformerConfig] = None,
        dual_retriever: Optional[DualRetriever] = None,
        llm: Optional[LLM] = None,
    ) -> None:
        self.config = config or QueryTransformerConfig()
        self.dual_retriever = dual_retriever or get_default_dual_retriever()

        # LLM utilis√© pour g√©n√©rer les variantes
        self.llm: Optional[LLM] = llm or Settings.llm
        if self.llm is None and self.config.enabled:
            logger.warning(
                "RAGFusionQueryTransformer : aucun LLM configur√© (Settings.llm est None). "
                "La g√©n√©ration de variantes sera d√©sactiv√©e."
            )
            self.config.enabled = False

        logger.info(
            "RAGFusionQueryTransformer initialis√© (num_variants=%d, temp=%.2f)",
            self.config.num_variants,
            self.config.temperature,
        )

    # --------------------------------------------------------------
    # 1.1 G√©n√©ration de variantes de requ√™tes
    # --------------------------------------------------------------
    def _generate_variants(self, question: str) -> List[str]:
        """
        G√©n√®re une liste de variantes de la question en utilisant un LLM.
        La question originale est toujours incluse en premi√®re position.
        """
        question = question.strip()
        if not question:
            return []

        # fallback : pas de variantes si d√©sactiv√© ou pas de LLM
        if not self.config.enabled or self.llm is None:
            return [question]

        system_prompt = (
            "Tu es un assistant sp√©cialis√© en recherche d'information financi√®re. "
            "Pour une question utilisateur donn√©e, tu dois proposer plusieurs "
            "reformulations naturelles qui pr√©servent le m√™me sens, pour "
            "am√©liorer la recherche dans une base de connaissances.\n\n"
            "Contraintes :\n"
            "- 1 reformulation par ligne\n"
            "- Pas de num√©rotation\n"
            "- Pas de commentaire autour, uniquement les variantes\n"
        )

        user_prompt = (
            f"Question utilisateur :\n{question}\n\n"
            f"G√©n√®re {self.config.num_variants - 1} reformulations diff√©rentes."
        )

        messages = [
            ChatMessage(role=MessageRole.SYSTEM, content=system_prompt),
            ChatMessage(role=MessageRole.USER, content=user_prompt),
        ]

        try:
            resp = self.llm.chat(messages=messages, temperature=self.config.temperature)
            raw_text = resp.message.content or ""
            lines = [l.strip() for l in raw_text.split("\n") if l.strip()]
            # on prend au max num_variants - 1 lignes
            variants = lines[: max(0, self.config.num_variants - 1)]
        except Exception as e:
            logger.exception(
                "Erreur lors de la g√©n√©ration de variantes de requ√™te : %s", e
            )
            variants = []

        # on s'assure que la question est en premi√®re position
        all_q = [question]
        for v in variants:
            if v not in all_q:
                all_q.append(v)

        return all_q

    # --------------------------------------------------------------
    # 1.2 RAG Fusion : retrieve_with_fusion
    # --------------------------------------------------------------
    def retrieve_with_fusion(self, question: str) -> RAGFusionQueryResult:
        """
        Pipeline complet :
          1) G√©n√®re des variantes de la question
          2) Appelle DualRetriever pour chaque variante
          3) Fusionne les r√©sultats avec d√©duplication
        """
        question = question.strip()
        if not question:
            return RAGFusionQueryResult(vector_nodes=[], kg_facts=[], all_queries=[])

        # 1) G√©n√©ration des variantes
        all_queries = self._generate_variants(question)
        logger.info("Requ√™tes RAG Fusion : %s", all_queries)

        # 2) Appels au DualRetriever
        all_vector_nodes: List[NodeWithScore] = []
        all_kg_facts: List[Dict[str, Any]] = []

        for q in all_queries:
            dr_result: DualRetrieverResult = self.dual_retriever.retrieve(q)
            all_vector_nodes.extend(dr_result.vector_nodes)
            all_kg_facts.extend(dr_result.kg_facts)

        # 3) Fusion / d√©duplication des r√©sultats
        dedup_vector = self._deduplicate_nodes(all_vector_nodes)
        dedup_kg = self._deduplicate_kg_facts(all_kg_facts)

        logger.info(
            "RAG Fusion fini pour %r ‚Üí %d nodes, %d facts",
            question,
            len(dedup_vector),
            len(dedup_kg),
        )

        return RAGFusionQueryResult(
            vector_nodes=dedup_vector,
            kg_facts=dedup_kg,
            all_queries=all_queries,
        )

    # --------------------------------------------------------------
    # 1.3 D√©duplication nodes & facts
    # --------------------------------------------------------------
    @staticmethod
    def _deduplicate_nodes(nodes: List[NodeWithScore]) -> List[NodeWithScore]:
        seen_ids = set()
        dedup: List[NodeWithScore] = []
        for n in nodes:
            node_id = n.node.node_id
            if node_id in seen_ids:
                continue
            seen_ids.add(node_id)
            dedup.append(n)
        return dedup

    @staticmethod
    def _deduplicate_kg_facts(
        facts: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        seen_ids = set()
        dedup: List[Dict[str, Any]] = []
        for f in facts:
            fid = f.get("id")
            if fid is not None and fid in seen_ids:
                continue
            if fid is not None:
                seen_ids.add(fid)
            dedup.append(f)
        return dedup


# ----------------------------------------------------------------------
# 2. Helper global
# ----------------------------------------------------------------------
def get_default_query_transformer(
    dual_retriever: Optional[DualRetriever] = None,
) -> RAGFusionQueryTransformer:
    return RAGFusionQueryTransformer(
        config=QueryTransformerConfig(),
        dual_retriever=dual_retriever or get_default_dual_retriever(),
    )


# ----------------------------------------------------------------------
# 3. Petit main de test
# ----------------------------------------------------------------------
if __name__ == "__main__":
    import logging

    logging.basicConfig(level=logging.INFO)

    qt = get_default_query_transformer()
    q = "Quel est le montant de la dette √† long terme d'Apple en 2025 ?"
    res = qt.retrieve_with_fusion(q)

    print("Queries utilis√©es :", res.all_queries)
    print("Vector nodes :", len(res.vector_nodes))
    print("KG facts :", len(res.kg_facts))
